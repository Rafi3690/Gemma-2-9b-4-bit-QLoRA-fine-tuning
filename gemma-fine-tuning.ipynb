{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":66631,"databundleVersionId":8346466,"sourceType":"competition"}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U \"transformers>=4.42.3\" bitsandbytes accelerate peft","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-18T15:07:18.718624Z","iopub.execute_input":"2026-01-18T15:07:18.718863Z","iopub.status.idle":"2026-01-18T15:07:38.379048Z","shell.execute_reply.started":"2026-01-18T15:07:18.718840Z","shell.execute_reply":"2026-01-18T15:07:38.378199Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers>=4.42.3 in /usr/local/lib/python3.12/dist-packages (4.57.1)\nCollecting transformers>=4.42.3\n  Downloading transformers-4.57.6-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting bitsandbytes\n  Downloading bitsandbytes-0.49.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\nCollecting accelerate\n  Downloading accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.17.1)\nCollecting peft\n  Downloading peft-0.18.1-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers>=4.42.3) (3.20.3)\nRequirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.42.3) (0.36.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.42.3) (2.0.2)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.42.3) (26.0rc2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.42.3) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.42.3) (2025.11.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers>=4.42.3) (2.32.5)\nRequirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.42.3) (0.22.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.42.3) (0.6.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.42.3) (4.67.1)\nRequirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.8.0+cu126)\nRequirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.42.3) (2025.10.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.42.3) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.42.3) (1.2.1rc0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.4.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.42.3) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.42.3) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.42.3) (2.6.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.42.3) (2026.1.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\nDownloading transformers-4.57.6-py3-none-any.whl (12.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.49.1-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading accelerate-1.12.0-py3-none-any.whl (380 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.9/380.9 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading peft-0.18.1-py3-none-any.whl (556 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.0/557.0 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: transformers, bitsandbytes, accelerate, peft\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.57.1\n    Uninstalling transformers-4.57.1:\n      Successfully uninstalled transformers-4.57.1\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 1.11.0\n    Uninstalling accelerate-1.11.0:\n      Successfully uninstalled accelerate-1.11.0\n  Attempting uninstall: peft\n    Found existing installation: peft 0.17.1\n    Uninstalling peft-0.17.1:\n      Successfully uninstalled peft-0.17.1\nSuccessfully installed accelerate-1.12.0 bitsandbytes-0.49.1 peft-0.18.1 transformers-4.57.6\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport copy\nfrom dataclasses import dataclass\n\nimport numpy as np\nimport torch\nfrom datasets import Dataset\nfrom transformers import (\n    BitsAndBytesConfig,\n    Gemma2ForSequenceClassification,\n    GemmaTokenizerFast,\n    Gemma2Config,\n    PreTrainedTokenizerBase, \n    EvalPrediction,\n    Trainer,\n    TrainingArguments,\n    DataCollatorWithPadding,\n)\nfrom peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, TaskType\nfrom sklearn.metrics import log_loss, accuracy_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T15:11:00.322490Z","iopub.execute_input":"2026-01-18T15:11:00.323245Z","iopub.status.idle":"2026-01-18T15:11:30.292760Z","shell.execute_reply.started":"2026-01-18T15:11:00.323200Z","shell.execute_reply":"2026-01-18T15:11:30.292165Z"}},"outputs":[{"name":"stderr","text":"2026-01-18 15:11:15.221425: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1768749075.416014      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1768749075.475174      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1768749075.961894      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768749075.961930      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768749075.961933      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768749075.961936      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"@dataclass\nclass Config:\n    output_dir: str = \"output\"\n    checkpoint: str = \"unsloth/gemma-2-9b-it-bnb-4bit\" \n    max_length: int = 1024\n    n_splits: int = 5\n    fold_idx: int = 0\n    optim_type: str = \"adamw_8bit\"\n    per_device_train_batch_size: int = 2\n    gradient_accumulation_steps: int = 2  \n    per_device_eval_batch_size: int = 8\n    n_epochs: int = 1\n    freeze_layers: int = 16  \n    lr: float = 2e-4\n    warmup_steps: int = 20\n    lora_r: int = 16\n    lora_alpha: float = lora_r * 2\n    lora_dropout: float = 0.05\n    lora_bias: str = \"none\"\n    \nconfig = Config()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T15:12:54.617720Z","iopub.execute_input":"2026-01-18T15:12:54.618048Z","iopub.status.idle":"2026-01-18T15:12:54.624818Z","shell.execute_reply.started":"2026-01-18T15:12:54.618017Z","shell.execute_reply":"2026-01-18T15:12:54.624211Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"output\",\n    overwrite_output_dir=True,\n    report_to=\"none\",\n    num_train_epochs=config.n_epochs,\n    per_device_train_batch_size=config.per_device_train_batch_size,\n    gradient_accumulation_steps=config.gradient_accumulation_steps,\n    per_device_eval_batch_size=config.per_device_eval_batch_size,\n    logging_steps=10,\n    eval_strategy=\"epoch\",\n    save_strategy=\"steps\",\n    save_steps=200,\n    optim=config.optim_type,\n    fp16=True,\n    learning_rate=config.lr,\n    warmup_steps=config.warmup_steps,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T15:14:42.267866Z","iopub.execute_input":"2026-01-18T15:14:42.268506Z","iopub.status.idle":"2026-01-18T15:14:42.472615Z","shell.execute_reply.started":"2026-01-18T15:14:42.268475Z","shell.execute_reply":"2026-01-18T15:14:42.471959Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"lora_config = LoraConfig(\n    r=config.lora_r,\n    lora_alpha=config.lora_alpha,\n    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\"],\n    layers_to_transform=[i for i in range(42) if i >= config.freeze_layers],\n    lora_dropout=config.lora_dropout,\n    bias=config.lora_bias,\n    task_type=TaskType.SEQ_CLS,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T15:14:55.645991Z","iopub.execute_input":"2026-01-18T15:14:55.646637Z","iopub.status.idle":"2026-01-18T15:14:55.651284Z","shell.execute_reply.started":"2026-01-18T15:14:55.646604Z","shell.execute_reply":"2026-01-18T15:14:55.650626Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"tokenizer = GemmaTokenizerFast.from_pretrained(config.checkpoint)\ntokenizer.add_eos_token = True \ntokenizer.padding_side = \"right\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T15:15:05.342021Z","iopub.execute_input":"2026-01-18T15:15:05.342660Z","iopub.status.idle":"2026-01-18T15:15:10.671905Z","shell.execute_reply.started":"2026-01-18T15:15:05.342630Z","shell.execute_reply":"2026-01-18T15:15:10.671054Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b04e1c2a7ffa4b33ae1660736856bcf0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3bd47c096f94e9ebd7daa7ea1b992ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba2b97692b16498599841ca0bc04e064"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"819c5fa75ab1436393fa35dc922c326a"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"model = Gemma2ForSequenceClassification.from_pretrained(\n    config.checkpoint,\n    num_labels=3,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n)\nmodel.config.use_cache = False\nmodel = prepare_model_for_kbit_training(model)\nmodel = get_peft_model(model, lora_config)\nmodel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T15:15:25.533077Z","iopub.execute_input":"2026-01-18T15:15:25.533531Z","iopub.status.idle":"2026-01-18T15:15:55.940160Z","shell.execute_reply.started":"2026-01-18T15:15:25.533486Z","shell.execute_reply":"2026-01-18T15:15:55.939415Z"}},"outputs":[{"name":"stderr","text":"`torch_dtype` is deprecated! Use `dtype` instead!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a760e3c5c84455bbcfe782fe36ab9ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/6.13G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82a8b0692aac4266a4ab4835a589c975"}},"metadata":{}},{"name":"stderr","text":"Some weights of Gemma2ForSequenceClassification were not initialized from the model checkpoint at unsloth/gemma-2-9b-it-bnb-4bit and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"PeftModelForSequenceClassification(\n  (base_model): LoraModel(\n    (model): Gemma2ForSequenceClassification(\n      (model): Gemma2Model(\n        (embed_tokens): Embedding(256000, 3584, padding_idx=0)\n        (layers): ModuleList(\n          (0-15): 16 x Gemma2DecoderLayer(\n            (self_attn): Gemma2Attention(\n              (q_proj): Linear4bit(in_features=3584, out_features=4096, bias=False)\n              (k_proj): Linear4bit(in_features=3584, out_features=2048, bias=False)\n              (v_proj): Linear4bit(in_features=3584, out_features=2048, bias=False)\n              (o_proj): Linear4bit(in_features=4096, out_features=3584, bias=False)\n            )\n            (mlp): Gemma2MLP(\n              (gate_proj): Linear4bit(in_features=3584, out_features=14336, bias=False)\n              (up_proj): Linear4bit(in_features=3584, out_features=14336, bias=False)\n              (down_proj): Linear4bit(in_features=14336, out_features=3584, bias=False)\n              (act_fn): GELUTanh()\n            )\n            (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n            (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n            (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n            (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n          )\n          (16-41): 26 x Gemma2DecoderLayer(\n            (self_attn): Gemma2Attention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=3584, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=3584, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=3584, out_features=2048, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=3584, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=2048, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=3584, out_features=2048, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=3584, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=2048, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): Linear4bit(in_features=4096, out_features=3584, bias=False)\n            )\n            (mlp): Gemma2MLP(\n              (gate_proj): Linear4bit(in_features=3584, out_features=14336, bias=False)\n              (up_proj): Linear4bit(in_features=3584, out_features=14336, bias=False)\n              (down_proj): Linear4bit(in_features=14336, out_features=3584, bias=False)\n              (act_fn): GELUTanh()\n            )\n            (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n            (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n            (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n            (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n          )\n        )\n        (norm): Gemma2RMSNorm((3584,), eps=1e-06)\n        (rotary_emb): Gemma2RotaryEmbedding()\n      )\n      (score): ModulesToSaveWrapper(\n        (original_module): Linear(in_features=3584, out_features=3, bias=False)\n        (modules_to_save): ModuleDict(\n          (default): Linear(in_features=3584, out_features=3, bias=False)\n        )\n      )\n    )\n  )\n)"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"model.print_trainable_parameters()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T15:16:00.406927Z","iopub.execute_input":"2026-01-18T15:16:00.408198Z","iopub.status.idle":"2026-01-18T15:16:00.418259Z","shell.execute_reply.started":"2026-01-18T15:16:00.408152Z","shell.execute_reply":"2026-01-18T15:16:00.417531Z"}},"outputs":[{"name":"stdout","text":"trainable params: 7,891,456 || all params: 9,249,608,192 || trainable%: 0.0853\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"ds = Dataset.from_csv(\"/kaggle/input/lmsys-chatbot-arena/train.csv\")\nds = ds.select(torch.arange(100)) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T15:16:03.797056Z","iopub.execute_input":"2026-01-18T15:16:03.797835Z","iopub.status.idle":"2026-01-18T15:16:07.061061Z","shell.execute_reply.started":"2026-01-18T15:16:03.797806Z","shell.execute_reply":"2026-01-18T15:16:07.060529Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57899466b64a4c2ebae2525048893908"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"ds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T15:16:11.486987Z","iopub.execute_input":"2026-01-18T15:16:11.487788Z","iopub.status.idle":"2026-01-18T15:16:11.492484Z","shell.execute_reply.started":"2026-01-18T15:16:11.487755Z","shell.execute_reply":"2026-01-18T15:16:11.491860Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['id', 'model_a', 'model_b', 'prompt', 'response_a', 'response_b', 'winner_model_a', 'winner_model_b', 'winner_tie'],\n    num_rows: 100\n})"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"class CustomTokenizer:\n    def __init__(self, tokenizer: PreTrainedTokenizerBase, max_length: int) -> None:\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        \n    def __call__(self, batch: dict) -> dict:\n        prompt = [\"<prompt>: \" + self.process_text(t) for t in batch.get(\"prompt\", [])]\n        response_a = [\"\\n\\n<response_a>: \" + self.process_text(t) for t in batch.get(\"response_a\", [])]\n        response_b = [\"\\n\\n<response_b>: \" + self.process_text(t) for t in batch.get(\"response_b\", [])]\n        \n        texts = [p + r_a + r_b for p, r_a, r_b in zip(prompt, response_a, response_b)]\n        tokenized = self.tokenizer(\n            texts,\n            max_length=self.max_length,\n            truncation=True,\n            padding=\"max_length\"\n        )\n        \n        labels = []\n        for a_win, b_win in zip(batch.get(\"winner_model_a\", []), batch.get(\"winner_model_b\", [])):\n            if a_win:\n                label = 0\n            elif b_win:\n                label = 1\n            else:\n                label = 2\n            labels.append(label)\n        \n        return {**tokenized, \"labels\": labels}\n    \n    @staticmethod\n    def process_text(text: str) -> str:\n        if text is None:\n            return \"\"\n        text = str(text)\n        text = text.replace(\"\\\\/\", \"/\")\n        return text.strip()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T15:20:58.876512Z","iopub.execute_input":"2026-01-18T15:20:58.876890Z","iopub.status.idle":"2026-01-18T15:20:58.885084Z","shell.execute_reply.started":"2026-01-18T15:20:58.876863Z","shell.execute_reply":"2026-01-18T15:20:58.884490Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"encode = CustomTokenizer(tokenizer, max_length=config.max_length)\nds = ds.map(encode, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T15:21:00.750098Z","iopub.execute_input":"2026-01-18T15:21:00.750448Z","iopub.status.idle":"2026-01-18T15:21:01.263449Z","shell.execute_reply.started":"2026-01-18T15:21:00.750419Z","shell.execute_reply":"2026-01-18T15:21:01.262702Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c33b9c15499c40c68ec88cf5bf83be14"}},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"def compute_metrics(eval_preds: EvalPrediction) -> dict:\n    preds = eval_preds.predictions\n    labels = eval_preds.label_ids\n    probs = torch.from_numpy(preds).float().softmax(-1).numpy()\n    loss = log_loss(y_true=labels, y_pred=probs)\n    acc = accuracy_score(y_true=labels, y_pred=preds.argmax(-1))\n    return {\"acc\": acc, \"log_loss\": loss}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T15:21:06.493371Z","iopub.execute_input":"2026-01-18T15:21:06.493671Z","iopub.status.idle":"2026-01-18T15:21:06.499412Z","shell.execute_reply.started":"2026-01-18T15:21:06.493646Z","shell.execute_reply":"2026-01-18T15:21:06.498610Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"folds = [\n    (\n        [i for i in range(len(ds)) if i % config.n_splits != fold_idx],\n        [i for i in range(len(ds)) if i % config.n_splits == fold_idx]\n    ) \n    for fold_idx in range(config.n_splits)\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T15:21:08.761026Z","iopub.execute_input":"2026-01-18T15:21:08.761487Z","iopub.status.idle":"2026-01-18T15:21:08.765923Z","shell.execute_reply.started":"2026-01-18T15:21:08.761459Z","shell.execute_reply":"2026-01-18T15:21:08.765163Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"train_idx, eval_idx = folds[config.fold_idx]\n\ntrainer = Trainer(\n    args=training_args, \n    model=model,\n    tokenizer=tokenizer,\n    train_dataset=ds.select(train_idx),\n    eval_dataset=ds.select(eval_idx),\n    compute_metrics=compute_metrics,\n    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n)\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T15:32:08.826194Z","iopub.execute_input":"2026-01-18T15:32:08.826590Z","iopub.status.idle":"2026-01-18T15:38:45.007246Z","shell.execute_reply.started":"2026-01-18T15:32:08.826560Z","shell.execute_reply":"2026-01-18T15:38:45.006436Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_55/2739703425.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [20/20 06:16, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Acc</th>\n      <th>Log Loss</th>\n      <th>Runtime</th>\n      <th>Samples Per Second</th>\n      <th>Steps Per Second</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>2.123800</td>\n      <td>1.400636</td>\n      <td>0.400000</td>\n      <td>1.400678</td>\n      <td>25.358100</td>\n      <td>0.789000</td>\n      <td>0.118000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=20, training_loss=2.840992736816406, metrics={'train_runtime': 395.6919, 'train_samples_per_second': 0.202, 'train_steps_per_second': 0.051, 'total_flos': 4095395852451840.0, 'train_loss': 2.840992736816406, 'epoch': 1.0})"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"test_ds = Dataset.from_csv(\"/kaggle/input/lmsys-chatbot-arena/test.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T15:39:00.492784Z","iopub.execute_input":"2026-01-18T15:39:00.493684Z","iopub.status.idle":"2026-01-18T15:39:00.503794Z","shell.execute_reply.started":"2026-01-18T15:39:00.493642Z","shell.execute_reply":"2026-01-18T15:39:00.503194Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"def build_text(row):\n    def clean(x):\n        if x is None:\n            return \"\"\n        return str(x).replace(\"\\\\/\", \"/\").strip()\n\n    return (\n        \"<prompt>: \" + clean(row[\"prompt\"]) +\n        \"\\n\\n<response_a>: \" + clean(row[\"response_a\"]) +\n        \"\\n\\n<response_b>: \" + clean(row[\"response_b\"])\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T15:42:16.960003Z","iopub.execute_input":"2026-01-18T15:42:16.960528Z","iopub.status.idle":"2026-01-18T15:42:16.965509Z","shell.execute_reply.started":"2026-01-18T15:42:16.960499Z","shell.execute_reply":"2026-01-18T15:42:16.964807Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"texts = [build_text(test_ds[i]) for i in range(len(test_ds))]\n\ninputs = tokenizer(\n    texts,\n    max_length=config.max_length,\n    truncation=True,\n    padding=True,\n    return_tensors=\"pt\"\n).to(model.device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T15:42:26.237567Z","iopub.execute_input":"2026-01-18T15:42:26.238379Z","iopub.status.idle":"2026-01-18T15:42:26.251544Z","shell.execute_reply.started":"2026-01-18T15:42:26.238346Z","shell.execute_reply":"2026-01-18T15:42:26.250686Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"model.eval()\nwith torch.no_grad():\n    outputs = model(**inputs)\n    logits = outputs.logits\n    probs = torch.softmax(logits, dim=-1)\n    preds = probs.argmax(dim=-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T15:42:42.191432Z","iopub.execute_input":"2026-01-18T15:42:42.192148Z","iopub.status.idle":"2026-01-18T15:42:46.270277Z","shell.execute_reply.started":"2026-01-18T15:42:42.192101Z","shell.execute_reply":"2026-01-18T15:42:46.269618Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"label_map = [\"Model A wins\", \"Model B wins\", \"Tie\"]\n\nfor i in range(len(test_ds)):\n    print(\"=\" * 80)\n    print(\"PROMPT:\\n\", test_ds[i][\"prompt\"])\n    print(\"\\nRESPONSE A:\\n\", test_ds[i][\"response_a\"])\n    print(\"\\nRESPONSE B:\\n\", test_ds[i][\"response_b\"])\n    print(\"\\nMODEL DECISION:\", label_map[preds[i].item()])\n    print(\"PROBABILITIES:\", probs[i].cpu().numpy())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-18T15:42:53.143427Z","iopub.execute_input":"2026-01-18T15:42:53.144046Z","iopub.status.idle":"2026-01-18T15:42:53.152231Z","shell.execute_reply.started":"2026-01-18T15:42:53.144014Z","shell.execute_reply":"2026-01-18T15:42:53.151488Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nPROMPT:\n [\"I have three oranges today, I ate an orange yesterday. How many oranges do I have?\"]\n\nRESPONSE A:\n [\"You have two oranges today.\"]\n\nRESPONSE B:\n [\"You still have three oranges. Eating an orange yesterday does not affect the number of oranges you have today.\"]\n\nMODEL DECISION: Model A wins\nPROBABILITIES: [0.60007775 0.31345168 0.08647051]\n================================================================================\nPROMPT:\n [\"You are a mediator in a heated political debate between two opposing parties. Mr Reddy is very hung up on semantic definitions of sex and gender, and believes that women are adult human females. Meanwhile Ms Blue is extremely fluid with definitions and does not care about truth. He (Ms blue uses he\\/him pronouns) insists that anybody can be any gender, gametes don't mean anything, and that men can get pregnant. You, Mr Goddy are tasked with helping them both find a middle ground.\"]\n\nRESPONSE A:\n [\"Thank you for sharing the details of the situation. As a mediator, I understand the importance of finding a middle ground that both parties can agree upon.\\n\\nIt is important to recognize that language and definitions can be complex and can vary depending on cultural and societal norms. At the same time, it is also important to acknowledge the biological differences between males and females.\\n\\nOne possible approach to finding a middle ground could be to focus on respecting individuals' self-identification and autonomy while also acknowledging the biological differences between males and females. This could involve using inclusive language that reflects individuals' gender identities while also recognizing the importance of biological sex in certain contexts, such as medical treatment and reproductive health.\\n\\nIt may also be helpful to explore ways to create a more inclusive society where individuals of all gender identities are valued and respected. This could involve promoting education and awareness about gender diversity and creating policies and practices that support individuals' gender identities and expression.\\n\\nUltimately, the goal of mediation is to find a solution that meets the needs and concerns of both parties. By focusing on mutual respect, open communication, and a willingness to find common ground, it is possible to reach a resolution that allows both parties to move forward in a positive and productive way.\"]\n\nRESPONSE B:\n [\"Mr Reddy and Ms Blue both have valid points in their arguments. On one hand, Mr Reddy is correct that women are adult human females, as defined by their biological and physical characteristics. However, Ms Blue is right that gender is a more fluid concept and that people can identify with any gender they choose. A compromise could be that gender is defined by an individual's self-identification, while sex is defined by their biological characteristics.\"]\n\nMODEL DECISION: Model A wins\nPROBABILITIES: [0.63896865 0.23221146 0.12881985]\n================================================================================\nPROMPT:\n [\"How to initialize the classification head when I do transfer learning. For example, I have a pre-trained vision transformer on ImageNet, and now I want to finetune it on StanfordCars\",\"I want to do full finetuning\"]\n\nRESPONSE A:\n [\"When you want to initialize the classification head for transfer learning, you can follow these steps:\\n\\n  1. Load the pre-trained model: First, load the pre-trained vision transformer model on ImageNet. You can use popular deep learning libraries like PyTorch or TensorFlow to load the model.\\n  2. Freeze the pre-trained layers: Next, you need to freeze the pre-trained layers of the model so that they don't get updated during the training process. This is because the pre-trained layers have learned useful features that can be reused for the new task.\\n  3. Add a new classification head: Now, you need to add a new classification head to the model. The classification head is responsible for outputting the predicted class for a given input image. The size of the classification head depends on the number of classes in the new task. For example, if you are working on the StanfordCars dataset, which has 196 classes, you would need a classification head with 196 output neurons.\\n  4. Initialize the classification head: Initialize the weights of the classification head randomly or using pre-trained weights. This is important because the initial weights can have a significant impact on the performance of the model.\\n  5. Train the model: Finally, you can train the model on the new task using your labeled data. During training, only the weights of the classification head will be updated, while the weights of the frozen pre-trained layers will remain unchanged. This allows the model to learn task-specific features while leveraging the pre-trained features.\\n\\nNote that there are different ways to initialize the classification head, such as using Xavier initialization, Kaiming initialization, or He initialization. You can choose the initialization method that works best for your specific task and model architecture.\",\"If you want to do full finetuning of the pre-trained vision transformer on the StanfordCars dataset, you can follow these steps:\\n\\n  1. Load the pre-trained model: Load the pre-trained vision transformer model on ImageNet. You can use popular deep learning libraries like PyTorch or TensorFlow to load the model.\\n  2. Remove the last classification layer: The pre-trained model typically has a last classification layer that is specific to the ImageNet dataset. To adapt the model to the StanfordCars dataset, you need to remove this layer.\\n  3. Add a new classification head: Add a new classification head to the model. The classification head is responsible for outputting the predicted class for a given input image. The size of the classification head depends on the number of classes in the StanfordCars dataset, which has 196 classes. You can add a fully connected layer with 196 output neurons as the new classification head.\\n  4. Initialize the classification head: Initialize the weights of the classification head randomly or using pre-trained weights. This is important because the initial weights can have a significant impact on the performance of the model.\\n  5. Freeze the pre-trained layers: Freeze the pre-trained layers of the model so that they don't get updated during the training process. This is because the pre-trained layers have learned useful features that can be reused for the new task.\\n  6. Train the model: Finally, you can train the model on the StanfordCars dataset using your labeled data. During training, all the weights of the model will be updated, including the weights of the frozen pre-trained layers. This allows the model to learn task-specific features while leveraging the pre-trained features.\\n\\nNote that when you do full finetuning, you need to use a lower learning rate and a smaller number of training epochs compared to transfer learning, because the model has already learned a lot of useful features from the pre-trained weights. You can experiment with different learning rates and training schedules to find the best hyperparameters for your specific task and model architecture.\"]\n\nRESPONSE B:\n [\"To initialize the classification head when performing transfer learning, follow these steps:\\n\\n1. Load the pre-trained vision transformer model that was trained on ImageNet.\\n2. Replace the existing classification head with a new one suitable for the StanfordCars dataset.\\n3. Initialize the weights of the new classification head with random values or pre-trained weights if available.\\n4. Freeze the weights of the vision transformer backbone to prevent them from being updated during training.\\n5. Train the model on the StanfordCars dataset, fine-tuning the classification head while keeping the backbone frozen.\\n\\nHere's an example implementation in Python using PyTorch:\\n\\n```python\\nimport torch\\nimport torch.nn as nn\\nimport torchvision.models as models\\n\\n# Step 1: Load pre-trained vision transformer model\\nvision_transformer = models.vit_base_patch16_224(pretrained=True)\\n\\n# Step 2: Replace classification head\\nnum_classes = 196  # Number of classes in StanfordCars dataset\\nvision_transformer.head = nn.Linear(vision_transformer.head.in_features, num_classes)\\n\\n# Step 3: Initialize weights of new classification head\\nnn.init.xavier_uniform_(vision_transformer.head.weight)\\nnn.init.constant_(vision_transformer.head.bias, 0)\\n\\n# Step 4: Freeze the weights of the backbone\\nfor param in vision_transformer.parameters():\\n    param.requires_grad = False\\n\\n# Step 5: Train the model on StanfordCars dataset\\n# ...\\n```\\n\\nIn this example, we load the pre-trained vision transformer model using `torchvision.models.vit_base_patch16_224`. We then replace the `head` (classification head) of the model with a new linear layer (`nn.Linear`) that has the appropriate number of output classes for the StanfordCars dataset.\\n\\nAfter replacing the classification head, we initialize its weights using Xavier initialization (`nn.init.xavier_uniform_`) and set its biases to zero (`nn.init.constant_`).\\n\\nFinally, we freeze the weights of the vision transformer backbone by setting `requires_grad=False` for all parameters. This ensures that only the weights of the classification head will be updated during training on the StanfordCars dataset.\",\"If you want to perform full finetuning, where both the classification head and the backbone of the vision transformer are updated during training on the StanfordCars dataset, you can omit freezing the backbone weights. Here's an updated version of the code:\\n\\n```python\\nimport torch\\nimport torch.nn as nn\\nimport torchvision.models as models\\n\\n# Step 1: Load pre-trained vision transformer model\\nvision_transformer = models.vit_base_patch16_224(pretrained=True)\\n\\n# Step 2: Replace classification head\\nnum_classes = 196  # Number of classes in StanfordCars dataset\\nvision_transformer.head = nn.Linear(vision_transformer.head.in_features, num_classes)\\n\\n# Step 3: Initialize weights of new classification head\\nnn.init.xavier_uniform_(vision_transformer.head.weight)\\nnn.init.constant_(vision_transformer.head.bias, 0)\\n\\n# Step 4: Train the model on StanfordCars dataset\\n# ...\\n```\\n\\nIn this case, you can directly train the vision transformer model on the StanfordCars dataset without freezing any weights. During training, both the weights of the classification head and the backbone will be updated.\\n\\nKeep in mind that full finetuning may require more computational resources and a larger labeled dataset compared to freezing the backbone. It can help the model learn more specific features related to the StanfordCars dataset but may also increase the risk of overfitting if the dataset is small. Monitoring the training progress and adjusting hyperparameters, such as learning rate and regularization, can help mitigate overfitting.\"]\n\nMODEL DECISION: Model B wins\nPROBABILITIES: [0.10155431 0.8696186  0.02882712]\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}